{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w0Zoe1x3t2nT"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import psutil\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import random\n",
    "np.random.seed(0)\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense,LSTM,Activation,Dropout,BatchNormalization,Input,Embedding,Reshape,Concatenate, GRU\n",
    "from keras.layers import Flatten,Conv2D,MaxPooling2D,Bidirectional,concatenate\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import regularizers\n",
    "from keras import optimizers\n",
    "# import keras_metrics as km\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from multiprocessing import cpu_count,Pool \n",
    "import multiprocessing\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import recall_score,precision_score,f1_score,accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "from scipy import interp\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "# from keras_self_attention import SeqSelfAttention\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics\n",
    "\n",
    "from numpy import unique\n",
    "from pandas import read_csv\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Embedding\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.utils import plot_model\n",
    "from keras.layers import Dropout\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow import keras\n",
    "import tensorflow_model_optimization as tfmot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-9a1ad0d7256f>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-9a1ad0d7256f>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    import tflite-runtime.interpreter as tflite\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import tflite-runtime.interpreter as tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BXUuG8DZuGfp"
   },
   "outputs": [],
   "source": [
    "verbose = 2\n",
    "dropout=0.2\n",
    "VAL_SPLIT = 0.2\n",
    "patience = 15\n",
    "lr=0.01\n",
    "weight_decay = 0.0000\n",
    "lr_decay=1e-6\n",
    "ADD_ON_LAYERS = True\n",
    "ACT_PRIOR = 'sigmoid'\n",
    "ACT_POSTERIOR = 'relu'\n",
    "LSTM_UNIT = 128\n",
    "LSTM_UNIT1 = 64\n",
    "LSTM_UNIT2 = 32 \n",
    "GEOHASH_UNIT = 128\n",
    "EMBEDDING_UNIT = 128\n",
    "Embedding_outdim = 128\n",
    "NLP_UNIT = 128\n",
    "SEQ_UNIT = 256\n",
    "DENSE_CONCAT = 512\n",
    "CONV_UNIT = 32\n",
    "weights = np.array([1,1])\n",
    "timestep = 6\n",
    "remove= -timestep\n",
    "top_words = 500\n",
    "max_review_length = 50\n",
    "embedding_vecor_length = 32\n",
    "weight_decay = 0.0000\n",
    "dropout=0.2\n",
    "Embedding_outdim = 128\n",
    "output_dim=1\n",
    "ADD_ON_LAYERS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d6rPd2JFt3fJ"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(interpreter):\n",
    "  input_index0 = interpreter.get_input_details()[0][\"index\"]\n",
    "  input_index1 = interpreter.get_input_details()[1][\"index\"]\n",
    "  input_index2 = interpreter.get_input_details()[2][\"index\"]\n",
    "  output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "  # Run predictions on ever y image in the \"test\" dataset.\n",
    "  prediction_digits = []\n",
    "  X_test3=np.load(\"X_test3.npy\")\n",
    "  X_test2=np.load(\"X_test2.npy\")\n",
    "  X_test=np.load(\"X_test.npy\")\n",
    "  y_test3=np.load(\"y_test3.npy\")\n",
    "  for i, test_image in enumerate(X_test3):\n",
    "    if i % 1000 == 0:\n",
    "      print('Evaluated on {n} results so far.'.format(n=i))\n",
    "\n",
    "    test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
    "    #print(test_image.shape)\n",
    "    \n",
    "    interpreter.set_tensor(input_index0, test_image)\n",
    "    \n",
    "    test_image1= X_test[i]\n",
    "\n",
    "    test_image1 = np.expand_dims(test_image1, axis=0).astype(np.float32)\n",
    "    #print(test_image1.shape)\n",
    "    interpreter.set_tensor(input_index1, test_image1)\n",
    "\n",
    "    #for k, test_image2 in enumerate(X_test2):\n",
    "    test_image2 = X_test2[i]\n",
    "    test_image2 = np.expand_dims(test_image2, axis=0).astype(np.float32)\n",
    "    #print(test_image2.shape)\n",
    "    interpreter.set_tensor(input_index2, test_image2)\n",
    "\n",
    "\n",
    "\n",
    "    # Run inference.\n",
    "    interpreter.invoke()\n",
    "\n",
    "    # Post-processing: remove batch dimension and find the digit with highest\n",
    "    # probability.\n",
    "    output = interpreter.get_tensor(output_index)\n",
    "    #a=output.to_numpy()\n",
    "    # print(len(output))\n",
    "    \n",
    "    #digit = np.argmax(output()[0])\n",
    "    \n",
    "    #print(output)\n",
    "    \n",
    "    prediction_digits.append(output)\n",
    "    \n",
    "\n",
    "  print('\\n')\n",
    "  print(prediction_digits)\n",
    "  for i in range(0,len(prediction_digits)):\n",
    "    if prediction_digits[i]>=0.50:\n",
    "        prediction_digits[i]=1\n",
    "    else:\n",
    "        prediction_digits[i]=0\n",
    "  print(prediction_digits)\n",
    "  print(confusion_matrix(y_test3, prediction_digits))\n",
    "  print(classification_report(y_test3, prediction_digits))\n",
    "  # Compare prediction results with ground truth labels to calculate accuracy.\n",
    "  prediction_digits = np.array(prediction_digits)\n",
    "  accuracy = (prediction_digits == y_test3).mean()\n",
    "  return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JeOZyQ3bt4sC"
   },
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=quantized_and_pruned_tflite_model)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "test_accuracy = evaluate_model(interpreter)\n",
    "\n",
    "print('Pruned and quantized TFLite test_accuracy:', test_accuracy)\n",
    "print('Pruned TF test accuracy:', model_for_pruning_accuracy)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "tflite model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
